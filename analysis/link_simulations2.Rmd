---
title: "Log1p vs. Identity Simulations With Multiple Groups"
output:
  workflowr::wflow_html:
    code_folding: hide
date: "2024-05-20"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results='hide')
```

## Simulation

In another attempt to clarify the differences between the log1p model and the Poisson NMF model, I simulated data from the log1p model

\begin{align*}
y_{ij} &\sim Poisson(\lambda_{ij}) \\
\log(1 + \lambda_{ij}) &= h_{ij} \\
\boldsymbol{H} &= \boldsymbol{L} \boldsymbol{F}^{T},
\end{align*}

using the following scheme for $\boldsymbol{L}$ and $\boldsymbol{F}$:

All cells are loaded with a value of $1$ on factor $1$, which has very low expression for genes 1-250 and expression of $1.5$ on the log1p scale for genes 251-500. Then, the remaining cells all have probability $0.2$ of being loaded with a value of $1$ (and $0$ otherwise) on the following factors:

(2) Expressed (on the log1p scale) at $1.8$ on genes 210-260 and $0$ otherwise.
(3) Expressed at at $1.8$ on genes 250-300 and $0$ otherwise.
(4) Expressed at at $1.8$ on genes 290-340 and $0$ otherwise.

```{r}
library(Matrix)
set.seed(5)
n_genes <- 500
n_cells <- 2500
K <- 4
library(passPCA)
FF <- matrix(
  data = 0,
  nrow = n_genes,
  ncol = K
)

LL <- matrix(
  data = 0,
  nrow = n_cells,
  ncol = K
)

FF[, 1] <- c(rep(log(1.00225), 250), rep(log(1.5), 250))
FF[210:260, 2] <- 1.8
FF[250:300, 3] <- 1.8
FF[290:340, 4] <- 1.8

LL[, 1] <- 1

for (j in 2:K) {

  LL[, j] <- sample(c(0, 1), size = n_cells, replace = TRUE, prob = c(0.8, 0.2))

}

H <- tcrossprod(LL, FF)
Lambda <- exp(H) - 1

y <- rpois(n_cells * n_genes, lambda = as.vector(Lambda))
Y <- matrix(
  data = y,
  nrow = n_cells,
  ncol = n_genes
)
Y <- as(Y, "sparseMatrix")
```

For what it's worth, below is a structure plot of the true loadings matrix:

```{r}
fastTopics::structure_plot(LL)
```

And, here is a visualization of the factors:

```{r}
true_factor_df <- data.frame(
  val = c(
    FF[,1], FF[,2], FF[,3], FF[,4]
  ),
  factor = c(
    rep("1", 500), rep("2", 500), rep("3", 500), rep("4", 500)
  ),
  pos = c(rep(1:500, 4))
)
library(ggplot2)
ggplot(true_factor_df, aes(x = pos, y = val)) +
  geom_bar(stat = "identity") +  # Use bars to represent lambda values
  facet_wrap(~ factor) +          # Create a panel for each group
  labs(x = "Value", y = "Factor") +
  cowplot::theme_cowplot()  # Use a minimal theme for a clean look

```

Now, I fit both the log1p model with a global quadratic approximation to the terms in the log-likelihood with $0$ counts. I also fit a standard Poisson NMF model using `fastTopics`. I set the rank of the factorization to be 4 in both cases.

```{r}
ft_mod <- fastTopics::fit_poisson_nmf(Y, k=4, numiter = 250)

log1p_mod <- fit_factor_model_log1p_quad_approx_sparse(
  Y=Y, K = 4, approx_range = c(0, 1.25), maxiter = 250
)
```

First, we visualize the results of the log1p model after normalizing so that the largest value of each column of $\boldsymbol{L}$ is $1$.

```{r}
max_col <- apply(log1p_mod$U, 2, max)
log1p_LL <- sweep(log1p_mod$U, 2, max_col, FUN = "/")
log1p_FF <- sweep(log1p_mod$V, 2, max_col, FUN = "*")
```

First, a structure plot of the loadings:

```{r}
fastTopics::structure_plot(log1p_LL)
```
And here are the factors:

```{r}
log1p_factor_df <- data.frame(
  val = c(
    log1p_FF[,1], log1p_FF[,2], log1p_FF[,3], log1p_FF[,4]
  ),
  factor = c(
    rep("1", 500), rep("2", 500), rep("3", 500), rep("4", 500)
  ),
  pos = c(rep(1:500, 4))
)
library(ggplot2)
ggplot(log1p_factor_df, aes(x = pos, y = val)) +
  geom_bar(stat = "identity") +  # Use bars to represent lambda values
  facet_wrap(~ factor) +          # Create a panel for each group
  labs(x = "Position", y = "Factor") +
  cowplot::theme_cowplot()  # Use a minimal theme for a clean look

```

Overall, the fit looks pretty good. We might hope for the third factor to be a bit sparser on the genes with higher positions, and we would hope for the fourth factor to be constant from 250-500. These discrepancies from the true model could be due to lack of identifiability, only fitting the model on $2,500$ cells, or the approximation to the log-likelihood.

However, it's quite illuminating the look at the results of Poisson NMF on this dataset. Below is the structure plot:

```{r}
fastTopics::structure_plot(ft_mod)
```
And here are the factors:

```{r}
ft_factor_df <- data.frame(
  val = c(
    ft_mod$F[,1], ft_mod$F[,2], ft_mod$F[,3], ft_mod$F[,4]
  ),
  factor = c(
    rep("1", 500), rep("2", 500), rep("3", 500), rep("4", 500)
  ),
  pos = c(rep(1:500, 4))
)
library(ggplot2)
ggplot(ft_factor_df, aes(x = pos, y = val)) +
  geom_bar(stat = "identity") +  # Use bars to represent lambda values
  facet_wrap(~ factor) +          # Create a panel for each group
  labs(x = "Position", y = "Value") +
  cowplot::theme_cowplot()  # Use a minimal theme for a clean look

```

Most notably, we can see that the factors are generally dominated by the set of genes that are in the "overlapping" areas of the factors. For instance, factor 1 is driven by genes in the range of 250-260. These genes are (a) in the higher background group and (b) are involved in two of the other three factors. Similar patterns can be seen in the other factors in the "overlapping" regions.

Essentially, I believe the identity link has a difficult time representing multiplicative changes in gene expression, especially for genes which already have somewhat high expression at baseline.

# Using a normal likelihood as an approximation

I wanted to explore the effects of using a normal likelihood to approximate the distribution of the data conditional on $L$ and $F$. First, I used maximum likelihood to fit NMF to the log1p transformed counts. The results are shown below:

```{r}
Y2 <- MatrixExtra::mapSparse(Y, log1p)
```


```{r}
library(RcppML)
```

```{r}
NMF <- RcppML::nmf(Y2, k=4)
```

```{r}
NMF_LL <- NMF$w %*% diag(NMF$d)
NMF_FF <- t(NMF$h)

max_col <- apply(NMF_LL, 2, max)
NMF_LL <- sweep(NMF_LL, 2, max_col, FUN = "/")
NMF_FF <- sweep(NMF_FF, 2, max_col, FUN = "*")
```


```{r}
ft_factor_df <- data.frame(
  val = c(
    NMF_FF[,1], NMF_FF[,2], NMF_FF[,3], NMF_FF[,4]
  ),
  factor = c(
    rep("1", 500), rep("2", 500), rep("3", 500), rep("4", 500)
  ),
  pos = c(rep(1:500, 4))
)
library(ggplot2)
ggplot(ft_factor_df, aes(x = pos, y = val)) +
  geom_bar(stat = "identity") +  # Use bars to represent lambda values
  facet_wrap(~ factor) +          # Create a panel for each group
  labs(x = "Position", y = "Value") +
  cowplot::theme_cowplot()  # Use a minimal theme for a clean look
```

This looks relatively similar to the MLE of the log1p Poisson fit. However, this model perhaps deals slightly less well with the overlapping part of the gene expression programs.

Next, I used flashier fit NMF on the log1p transformed counts. I started with a greedy initialization. I'm using a constant value for S based on the flashier vignette. The results are shown below:

```{r}
library(flashier)
mhat = 1/nrow(Y2) #estimate of rate
xx = rpois(1e7, mhat) #random poisson
S1 <- sd(log(xx + 1)) #sd of log(X+1)
f <- flash(data = Y2, S = S1, backfit = T, greedy_Kmax = 4, ebnm_fn = ebnm::ebnm_point_exponential)
```

```{r}
max_col <- apply(f$L_pm, 2, max)
f_LL <- sweep(f$L_pm, 2, max_col, FUN = "/")
f_FF <- sweep(f$F_pm, 2, max_col, FUN = "*")
```

```{r}
ft_factor_df <- data.frame(
  val = c(
    f_FF[,1], f_FF[,2], f_FF[,3], f_FF[,4]
  ),
  factor = c(
    rep("1", 500), rep("2", 500), rep("3", 500), rep("4", 500)
  ),
  pos = c(rep(1:500, 4))
)
library(ggplot2)
ggplot(ft_factor_df, aes(x = pos, y = val)) +
  geom_bar(stat = "identity") +  # Use bars to represent lambda values
  facet_wrap(~ factor) +          # Create a panel for each group
  labs(x = "Position", y = "Value") +
  cowplot::theme_cowplot()  # Use a minimal theme for a clean look
```

These results look quite good. When compared to the MLE of the log1p Poisson model, the results look quite similar, except that there is significantly more shrinkage in the areas where we saw extraneous background showing up in the MLE (e.g. in factors 2 and 3).

Finally, I wanted to try to use Matthew's new approximation with flashier. First, I tried to start with a greedy initialization. However, flash is not able to find a single non-zero factor. I think the reason for this is that I am restricting the factors to be non-negative but the vast majority of the values in the matrix are -1. So, with only one factor, it may not be possible to fit the data any better than with all 0s for the means.

```{r}
Y3 <- as.matrix(Y2)
S3 <- Y3 / ((1 + Y3) ^ 2)
S3 <- apply(S3, c(1, 2), function(x){if(x == 0){1}else{x}})
Y3 <- apply(Y3, c(1, 2), function(x){if(x == 0){-1}else{x}})
```

```{r}
set.seed(1)
f2 <- flash(data = Y3, S = sqrt(S3), backfit = T, greedy_Kmax = 4, ebnm_fn = ebnm::ebnm_point_exponential)
```

Now, I try a greedy initialization of flashier (again using Matthew's approximation to transform the data and estimate the variance) with the MLE and then backfit:

```{r}
fit_flash_new_mle <- flash_init(data = Y3, S = sqrt(S3))
fit_flash_new_mle <- flash_factors_init(
  flash = fit_flash_new_mle,
  init = list(
    log1p_mod$U, log1p_mod$V
  ),
  ebnm_fn = ebnm::ebnm_point_exponential
)

fit_flash_new_mle <- flash_backfit(fit_flash_new_mle)
```
```{r}
f <- fit_flash_new_mle
max_col <- apply(f$L_pm, 2, max)
f_LL <- sweep(f$L_pm, 2, max_col, FUN = "/")
f_FF <- sweep(f$F_pm, 2, max_col, FUN = "*")

ft_factor_df <- data.frame(
  val = c(
    f_FF[,1], f_FF[,2], f_FF[,3], f_FF[,4]
  ),
  factor = c(
    rep("1", 500), rep("2", 500), rep("3", 500), rep("4", 500)
  ),
  pos = c(rep(1:500, 4))
)
library(ggplot2)
ggplot(ft_factor_df, aes(x = pos, y = val)) +
  geom_bar(stat = "identity") +  # Use bars to represent lambda values
  facet_wrap(~ factor) +          # Create a panel for each group
  labs(x = "Position", y = "Value") +
  cowplot::theme_cowplot()  # Use a minimal theme for a clean look
```
This looks very good, probably the best so far. These results are quite close to the true model. 

This begs the question, if I had initialized using the current flashier pipeline, would the results have been similar. I try this below:


```{r}
fit_flash_new_mle <- flash_init(data = Y2, S = S1)
fit_flash_new_mle <- flash_factors_init(
  flash = fit_flash_new_mle,
  init = list(
    log1p_mod$U, log1p_mod$V
  ),
  ebnm_fn = ebnm::ebnm_point_exponential
)

fit_flash_new_mle <- flash_backfit(fit_flash_new_mle)
```

```{r}
f <- fit_flash_new_mle
max_col <- apply(f$L_pm, 2, max)
f_LL <- sweep(f$L_pm, 2, max_col, FUN = "/")
f_FF <- sweep(f$F_pm, 2, max_col, FUN = "*")

ft_factor_df <- data.frame(
  val = c(
    f_FF[,1], f_FF[,2], f_FF[,3], f_FF[,4]
  ),
  factor = c(
    rep("1", 500), rep("2", 500), rep("3", 500), rep("4", 500)
  ),
  pos = c(rep(1:500, 4))
)
library(ggplot2)
ggplot(ft_factor_df, aes(x = pos, y = val)) +
  geom_bar(stat = "identity") +  # Use bars to represent lambda values
  facet_wrap(~ factor) +          # Create a panel for each group
  labs(x = "Position", y = "Value") +
  cowplot::theme_cowplot()  # Use a minimal theme for a clean look
```
The answer appears to be no...

# Greedy initialization using the MLE to initialize factors

Matthew suggested that the poor performance of the greedy initialization above could be due to the fact that `flashier`'s initializtion function does not take standard errors into account.

To remedy this, I will instead provide a custom initialization function to `flashier`. I will set the initial values in this function to the posterior expectations of `L` and `F`. Then, I will add an additional factor to maximize the likelihood of the Poisson log1p model using the un-transformed data Y.

```{r}
make_log1p_init_fn <- function(Y) {
  
  log1p_init_fn <- function(f) {
    
    if (is.null(f$EF)) {
      
      L_init <- matrix(
        data = rexp(n = nrow(Y), rate = 15),
        nrow = nrow(Y)
      )
      F_init <- matrix(
        data = rexp(n = ncol(Y), rate = 15),
        nrow = ncol(Y)
      )
      new_factor_num <- 1
      
    } else {
      
      L_init <- cbind(f$EF[[1]], rexp(n = nrow(Y), rate = 15))
      F_init <- cbind(f$EF[[2]], rexp(n = ncol(Y), rate = 15))
      new_factor_num <- 1 + ncol(f$EF[[1]])
      
    }
    
    new_fit <- passPCA::fit_factor_model_log1p_quad_approx_sparse(
      Y = Y,
      K = new_factor_num,
      maxiter = 15,
      init_U = L_init,
      init_V = F_init,
      update_idx = c(new_factor_num),
      approx_range = c(0, 1.25)
    )
    
    return(
      list(
        new_fit$U[,new_factor_num], new_fit$V[,new_factor_num]
      )
    )
    
  }
  
  return(log1p_init_fn)
  
}
```

```{r}
set.seed(1)
f_log1p_init <- flash_init(data = Y3, S = sqrt(S3))
f_log1p_init <- flash_greedy(
  flash = f_log1p_init,
  Kmax = 10, 
  ebnm_fn = ebnm::ebnm_point_exponential,
  init_fn = make_log1p_init_fn(Y)
)
```

Using this greedy approach, flash adds 5 factors, just 1 off from the truth. They are visualized below

```{r}
f <- f_log1p_init
max_col <- apply(f$L_pm, 2, max)
f_LL <- sweep(f$L_pm, 2, max_col, FUN = "/")
f_FF <- sweep(f$F_pm, 2, max_col, FUN = "*")

ft_factor_df <- data.frame(
  val = c(
    f_FF[,1], f_FF[,2], f_FF[,3], f_FF[,4], f_FF[,5]
  ),
  factor = c(
    rep("1", 500), rep("2", 500), rep("3", 500), rep("4", 500), rep("5", 500)
  ),
  pos = c(rep(1:500, 5))
)
library(ggplot2)
ggplot(ft_factor_df, aes(x = pos, y = val)) +
  geom_bar(stat = "identity") +  # Use bars to represent lambda values
  facet_wrap(~ factor) +          # Create a panel for each group
  labs(x = "Position", y = "Value") +
  cowplot::theme_cowplot()  # Use a minimal theme for a clean look
```

These look a bit wonky, but let's see if a backfit improves things...

```{r}
f_log1p_init <- flash_backfit(
  f_log1p_init
)
```
```{r}
f <- f_log1p_init
max_col <- apply(f$L_pm, 2, max)
f_LL <- sweep(f$L_pm, 2, max_col, FUN = "/")
f_FF <- sweep(f$F_pm, 2, max_col, FUN = "*")

ft_factor_df <- data.frame(
  val = c(
    f_FF[,1], f_FF[,2], f_FF[,3], f_FF[,4], f_FF[,5]
  ),
  factor = c(
    rep("1", 500), rep("2", 500), rep("3", 500), rep("4", 500), rep("5", 500)
  ),
  pos = c(rep(1:500, 5))
)
library(ggplot2)
ggplot(ft_factor_df, aes(x = pos, y = val)) +
  geom_bar(stat = "identity") +  # Use bars to represent lambda values
  facet_wrap(~ factor) +          # Create a panel for each group
  labs(x = "Position", y = "Value") +
  cowplot::theme_cowplot()  # Use a minimal theme for a clean look
```

Things seem to look better after the backfit. 
